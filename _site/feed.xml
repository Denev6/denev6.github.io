

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://denev6.github.io/</id>
  <title>Jin's Notes</title>
  <subtitle>AI, 수학, Python, Golang을 다루는 학생입니다.</subtitle>
  <updated>2025-02-14T08:21:52+09:00</updated>
  <author>
    <name>박성진</name>
    <uri>https://denev6.github.io/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="https://denev6.github.io/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="ko-KR"
    href="https://denev6.github.io/"/>
  <generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator>
  <rights> © 2025 박성진 </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Image Segmentation with FCN</title>
    <link href="https://denev6.github.io/computer-vision/2025/02/08/fcn.html" rel="alternate" type="text/html" title="Image Segmentation with FCN" />
    <published>2025-02-08T00:00:00+09:00</published>
  
    <updated>2025-02-08T00:00:00+09:00</updated>
  
    <id>https://denev6.github.io/computer-vision/2025/02/08/fcn.html</id>
    <content src="https://denev6.github.io/computer-vision/2025/02/08/fcn.html" />
    <author>
      <name>박성진</name>
    </author>

  
    
    <category term="Computer-Vision" />
    
  

  
    <summary>
      





      이미지 segmentation에 대해 다루며, CNN을 활용한 FCN(Fullly Convolutional Network)을 중심으로 소개한다. FCN은 논문 “Fully Convolutional Networks for Semantic Segmentation“에서 소개되었다.

Image Segmentation



이미지 segmentation은 픽셀 단위로 객체 클래스를 분류하는 문제를 말한다. 이는 각 픽셀마다 이미지 분류 문제를 푸는 것과 같다. c개의 레이블이 있다면 배경(0)을 하나의 레이블로 두고 총 c+1개의 레이블로 분류하는 문제가 된다.



기존의 CNN classification 모델은 2차원 feature map을 1차원으로 압축해 결과를 출력한다. 만약 2차원 정보를 유지한 채...
    </summary>
  

  </entry>

  
  <entry>
    <title>An Image is Worth 16x16 Words, Transformers For Image Recognition At Scale</title>
    <link href="https://denev6.github.io/paper-review/2025/02/06/vit.html" rel="alternate" type="text/html" title="An Image is Worth 16x16 Words, Transformers For Image Recognition At Scale" />
    <published>2025-02-06T00:00:00+09:00</published>
  
    <updated>2025-02-06T00:00:00+09:00</updated>
  
    <id>https://denev6.github.io/paper-review/2025/02/06/vit.html</id>
    <content src="https://denev6.github.io/paper-review/2025/02/06/vit.html" />
    <author>
      <name>박성진</name>
    </author>

  
    
    <category term="Paper-Review" />
    
  

  
    <summary>
      





      
  논문: arXiv
  공식 구현: Pytorch-vision
  분석 코드: Github


본문에 L000으로 적힌 링크는 줄번호로, 클릭하면 Pytorch에서 어떻게 구현되어 있는지 확인할 수 있다.

Abstract

Transformer는 자연어 처리 분야에서 활발히 사용되고 있지만, 비전(vision) 문제에 적용된 경우는 제한적이다. 우리는 이미지 조각을 순수한 transformer에 입력해 분류 문제를 풀었다. Vision Transformer(ViT)는 CNN과 비교해 SOTA를 달성했으며, 더 적은 연산 비용이 든다.

Introduction

Self-attention 구조의 transformer가 자연어 처리에서 좋은 성능을 보이고 있지만, 비전 분야는 여전히 CNN이 우세하다...
    </summary>
  

  </entry>

  
  <entry>
    <title>Deep Residual Learning for Image Recognition</title>
    <link href="https://denev6.github.io/paper-review/2025/02/04/resnet.html" rel="alternate" type="text/html" title="Deep Residual Learning for Image Recognition" />
    <published>2025-02-04T00:00:00+09:00</published>
  
    <updated>2025-02-07T08:47:57+09:00</updated>
  
    <id>https://denev6.github.io/paper-review/2025/02/04/resnet.html</id>
    <content src="https://denev6.github.io/paper-review/2025/02/04/resnet.html" />
    <author>
      <name>박성진</name>
    </author>

  
    
    <category term="Paper-Review" />
    
  

  
    <summary>
      





      
  논문: Deep Residual Learning for Image Recognition
  구현: Github: Pytorch-Vision


Abstract


  이전보다 더 깊은 모델을 학습
  레이어 입력을 참고하도록 재구성
  residual network는 깊은 모델의 정확도를 올림


Introduction

vanishing/exploding gradient가 모델 수렴을 방해한다. 이는 normalized initialization과 intermediate normalization layers로 해결할 수 있다.

하지만 degradation 문제도 발생한다. 정확도가 낮아지지 않고 training error가 얕은 모델보다 크다.



본 연구는 deep residual lear...
    </summary>
  

  </entry>

  
  <entry>
    <title>ImageNet Classification with Deep Convolutional Neural Networks</title>
    <link href="https://denev6.github.io/paper-review/2025/01/31/alexnet.html" rel="alternate" type="text/html" title="ImageNet Classification with Deep Convolutional Neural Networks" />
    <published>2025-01-31T00:00:00+09:00</published>
  
    <updated>2025-01-31T00:00:00+09:00</updated>
  
    <id>https://denev6.github.io/paper-review/2025/01/31/alexnet.html</id>
    <content src="https://denev6.github.io/paper-review/2025/01/31/alexnet.html" />
    <author>
      <name>박성진</name>
    </author>

  
    
    <category term="Paper-Review" />
    
  

  
    <summary>
      





      ImageNet Classification with Deep Convolutional Neural Networks: 논문은 AlexNet을 소개한 논문으로 CNN 모델의 각 레이어가 어떤 역할을 하는지 잘 분석했다.

논문을 정리한 글이며, CNN의 기본적인 개념을 생략하고 정리했다. 자세한 부분은 BLOG: CNN에 볼 수 있다.

본 글에서 분석을 위해 사용한 코드는 Github에 정리되어 있다.

Abstract


  ImageNet LSVRC-2012 대회에서 SOTA를 달성
  모델은 6000만 개의 파라미터와 650,000개 뉴런으로 구성
  5개의 convolutional layer + 3개의 fully-connected layer + 1000-way softmax
  non-satura...
    </summary>
  

  </entry>

  
  <entry>
    <title>Auto-Encoding Variational Bayes</title>
    <link href="https://denev6.github.io/computer-vision/2025/01/29/vae.html" rel="alternate" type="text/html" title="Auto-Encoding Variational Bayes" />
    <published>2025-01-29T00:00:00+09:00</published>
  
    <updated>2025-01-31T00:18:46+09:00</updated>
  
    <id>https://denev6.github.io/computer-vision/2025/01/29/vae.html</id>
    <content src="https://denev6.github.io/computer-vision/2025/01/29/vae.html" />
    <author>
      <name>박성진</name>
    </author>

  
    
    <category term="Computer-Vision" />
    
  

  
    <summary>
      





      Auto Encoder

Variational Auto-Encoding을 이해하기 위해 기본적인 Auto-Encoding을 알아야 한다.



Auto Encoder(AE)는 데이터를 압축하고 복원하는 단순한 모델이다. Linear layer을 통해 데이터 크기를 줄이고 복원한다. Auto Encoder 구성은 다음과 같다.


  Encoder: 데이터를 압축하는 신경망 (파란 부분)
  latent variable: 데이터가 압축된 벡터
  Decoder: 데이터를 복원하는 신경망 (초록 부분)


다른 표현으로 Encoder를 Recognition model, Decoder를 Reconstruction model이라고 부른다.

class Autoencoder(nn.Module):
    def ...
    </summary>
  

  </entry>

</feed>


